/*******************************************************************************
 * Copyright (C) 2024 MINRES Technologies GmbH
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *
 * 1. Redistributions of source code must retain the above copyright notice,
 *    this list of conditions and the following disclaimer.
 *
 * 2. Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 * 3. Neither the name of the copyright holder nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 *
 *******************************************************************************/
 <%
def floating_point = registers.find {it.name=='FCSR'} != null
def vector = registers.find {it.name=='vtype'} != null
def aes = functions.find { it.contains('aes') } != null
def nativeTypeSize(int size){
    if(size<=8) return 8; else if(size<=16) return 16; else if(size<=32) return 32; else return 64;
}
%>
// clang-format off
#include <iss/arch/${coreDef.name.toLowerCase()}.h>
#include <iss/debugger/gdb_session.h>
#include <iss/debugger/server.h>
#include <iss/iss.h>
#include <iss/asmjit/vm_base.h>
#include <asmjit/asmjit.h>
#include <util/logging.h>
#include <iss/instruction_decoder.h>
<%
if(floating_point) {%>
#include <vm/fp_functions.h>
<%}
if(vector){%>
#include <vm/new_vector_functions.h>
<%}
if(aes) {%>
#include <vm/aes_sbox.h>
<%}%>
#ifndef FMT_HEADER_ONLY
#define FMT_HEADER_ONLY
#endif
#include <fmt/format.h>

#include <array>
#include <iss/debugger/riscv_target_adapter.h>

#ifndef _MSC_VER
using int128_t = __int128;
using uint128_t = unsigned __int128;
namespace std {
template <> struct make_unsigned<__int128> { typedef unsigned __int128 type; };
template <> class __make_unsigned_selector<__int128 unsigned, false, false> {
public:
    typedef unsigned __int128 __type;
};
template <> struct is_signed<int128_t> { static constexpr bool value = true; };
template <> struct is_signed<uint128_t> { static constexpr bool value = false; };
template <> struct is_unsigned<int128_t> { static constexpr bool value = false; };
template <> struct is_unsigned<uint128_t> { static constexpr bool value = true; };
} // namespace std
#endif

namespace iss {
namespace asmjit {
namespace ${coreDef.name.toLowerCase()}{

using namespace ::asmjit;
using namespace iss::arch;
using namespace iss::debugger;

template <typename ARCH> class vm_impl : public iss::asmjit::vm_base<ARCH> {
public:
    using traits = arch::traits<ARCH>;
    using super = typename iss::asmjit::vm_base<ARCH>;
    using virt_addr_t = typename super::virt_addr_t;
    using phys_addr_t = typename super::phys_addr_t;
    using code_word_t = typename super::code_word_t;
    using mem_type_e = typename super::mem_type_e;
    using addr_t = typename super::addr_t;

<%if(vector) {%>
    static constexpr auto& vlseg = softvec_if::vlseg<traits::VLEN>;
    static constexpr auto& vsseg = softvec_if::vsseg<traits::VLEN>;
    static constexpr auto& vlsseg = softvec_if::vlsseg<traits::VLEN>;
    static constexpr auto& vssseg = softvec_if::vssseg<traits::VLEN>;
    static constexpr auto& vlxseg = softvec_if::vlxseg<traits::VLEN, traits::XLEN>;
    static constexpr auto& vsxseg = softvec_if::vsxseg<traits::VLEN, traits::XLEN>;
    static constexpr auto& vector_vector_op = softvec_if::vector_vector_op<traits::VLEN>;
    static constexpr auto& vector_imm_op = softvec_if::vector_imm_op<traits::VLEN>;
    static constexpr auto& vector_vector_wv = softvec_if::vector_vector_wv<traits::VLEN>;
    static constexpr auto& vector_imm_wv = softvec_if::vector_imm_wv<traits::VLEN>;
    static constexpr auto& vector_vector_ww = softvec_if::vector_vector_ww<traits::VLEN>;
    static constexpr auto& vector_imm_ww = softvec_if::vector_imm_ww<traits::VLEN>;
    static constexpr auto& vector_extend = softvec_if::vector_extend<traits::VLEN>;
    static constexpr auto& vector_vector_carry = softvec_if::vector_vector_carry<traits::VLEN>;
    static constexpr auto& vector_imm_carry = softvec_if::vector_imm_carry<traits::VLEN>;
    static constexpr auto& carry_vector_vector_op = softvec_if::carry_vector_vector_op<traits::VLEN>;
    static constexpr auto& carry_vector_imm_op = softvec_if::carry_vector_imm_op<traits::VLEN>;
    static constexpr auto& mask_vector_vector_op = softvec_if::mask_vector_vector_op<traits::VLEN>;
    static constexpr auto& mask_vector_imm_op = softvec_if::mask_vector_imm_op<traits::VLEN>;
    static constexpr auto& vector_vector_vw = softvec_if::vector_vector_vw<traits::VLEN>;
    static constexpr auto& vector_imm_vw = softvec_if::vector_imm_vw<traits::VLEN>;
    static constexpr auto& vector_vector_merge = softvec_if::vector_vector_merge<traits::VLEN>;
    static constexpr auto& vector_imm_merge = softvec_if::vector_imm_merge<traits::VLEN>;
    static constexpr auto& sat_vector_vector_op = softvec_if::sat_vector_vector_op<traits::VLEN>;
    static constexpr auto& sat_vector_imm_op = softvec_if::sat_vector_imm_op<traits::VLEN>;
    static constexpr auto& sat_vector_vector_vw = softvec_if::sat_vector_vector_vw<traits::VLEN>;
    static constexpr auto& sat_vector_imm_vw = softvec_if::sat_vector_imm_vw<traits::VLEN>;
    static constexpr auto& vector_red_op = softvec_if::vector_red_op<traits::VLEN>;
    static constexpr auto& vector_red_wv = softvec_if::vector_red_wv<traits::VLEN>;
    static constexpr auto& mask_mask_op = softvec_if::mask_mask_op<traits::VLEN>;
    static constexpr auto& vcpop = softvec_if::vcpop<traits::VLEN>;
    static constexpr auto& vfirst = softvec_if::vfirst<traits::VLEN>;
    static constexpr auto& mask_set_op = softvec_if::mask_set_op<traits::VLEN>;
    static constexpr auto& viota = softvec_if::viota<traits::VLEN>;
    static constexpr auto& vid = softvec_if::vid<traits::VLEN>;
    static constexpr auto& scalar_to_vector = softvec_if::scalar_to_vector<traits::VLEN>;
    static constexpr auto& scalar_from_vector = softvec_if::scalar_from_vector<traits::VLEN>;
    static constexpr auto& vector_slideup = softvec_if::vector_slideup<traits::VLEN>;
    static constexpr auto& vector_slidedown = softvec_if::vector_slidedown<traits::VLEN>;
    static constexpr auto& vector_slide1up = softvec_if::vector_slide1up<traits::VLEN>;
    static constexpr auto& vector_slide1down = softvec_if::vector_slide1down<traits::VLEN>;
    static constexpr auto& vector_vector_gather = softvec_if::vector_vector_gather<traits::VLEN>;
    static constexpr auto& vector_vector_gatherei16 = softvec_if::vector_vector_gatherei16<traits::VLEN>;
    static constexpr auto& vector_imm_gather = softvec_if::vector_imm_gather<traits::VLEN>;
    static constexpr auto& vector_compress = softvec_if::vector_compress<traits::VLEN>;
    static constexpr auto& vector_whole_move = softvec_if::vector_whole_move<traits::VLEN>;
    static constexpr auto& fp_scalar_from_vector = softvec_if::fp_scalar_from_vector<traits::VLEN>;
    static constexpr auto& fp_vector_slide1up = softvec_if::fp_vector_slide1up<traits::VLEN>;
    static constexpr auto& fp_vector_slide1down = softvec_if::fp_vector_slide1down<traits::VLEN>;
    static constexpr auto& fp_vector_red_op = softvec_if::fp_vector_red_op<traits::VLEN>;
    static constexpr auto& fp_vector_red_wv = softvec_if::fp_vector_red_wv<traits::VLEN>;
    static constexpr auto& fp_vector_vector_op = softvec_if::fp_vector_vector_op<traits::VLEN>;
    static constexpr auto& fp_vector_imm_op = softvec_if::fp_vector_imm_op<traits::VLEN>;
    static constexpr auto& fp_vector_vector_wv = softvec_if::fp_vector_vector_wv<traits::VLEN>;
    static constexpr auto& fp_vector_imm_wv = softvec_if::fp_vector_imm_wv<traits::VLEN>;
    static constexpr auto& fp_vector_vector_ww = softvec_if::fp_vector_vector_ww<traits::VLEN>;
    static constexpr auto& fp_vector_imm_ww = softvec_if::fp_vector_imm_ww<traits::VLEN>;
    static constexpr auto& fp_vector_unary_op = softvec_if::fp_vector_unary_op<traits::VLEN>;
    static constexpr auto& mask_fp_vector_vector_op = softvec_if::mask_fp_vector_vector_op<traits::VLEN>;
    static constexpr auto& mask_fp_vector_imm_op = softvec_if::mask_fp_vector_imm_op<traits::VLEN>;
    static constexpr auto& fp_vector_imm_merge = softvec_if::fp_vector_imm_merge<traits::VLEN>;
    static constexpr auto& fp_vector_unary_w = softvec_if::fp_vector_unary_w<traits::VLEN>;
    static constexpr auto& fp_vector_unary_n = softvec_if::fp_vector_unary_n<traits::VLEN>;
    static constexpr auto& vector_unary_op = softvec_if::vector_unary_op<traits::VLEN>;
<%}%>
    vm_impl();

    vm_impl(ARCH &core, unsigned core_id = 0, unsigned cluster_id = 0);

    void enableDebug(bool enable) { super::sync_exec = super::ALL_SYNC; }

    target_adapter_if *accquire_target_adapter(server_if *srv) override {
        debugger_if::dbg_enabled = true;
        if (vm_base<ARCH>::tgt_adapter == nullptr)
            vm_base<ARCH>::tgt_adapter = new riscv_target_adapter<ARCH>(srv, this->get_arch());
        return vm_base<ARCH>::tgt_adapter;
    }

protected:
    using super::get_ptr_for;
    using super::get_reg_for;
    using super::get_reg_for_Gp;
    using super::load_reg_from_mem;
    using super::load_reg_from_mem_Gp;
    using super::write_reg_to_mem;
    using super::gen_read_mem;
    using super::gen_write_mem;
    using super::gen_leave;
    using super::gen_sync;
   
    using this_class = vm_impl<ARCH>;
    using compile_func = continuation_e (this_class::*)(virt_addr_t&, code_word_t, jit_holder&);

    continuation_e gen_single_inst_behavior(virt_addr_t&, jit_holder&) override;
    enum globals_e {TVAL = 0, GLOBALS_SIZE};
    void gen_block_prologue(jit_holder& jh) override;
    void gen_block_epilogue(jit_holder& jh) override;
    inline const char *name(size_t index){return traits::reg_aliases.at(index);}
<%if(floating_point) {%>
    inline const char *fname(size_t index){return index < 32?name(index+traits::F0):"illegal";}   
<%}
if(vector) {%>
    inline const char* vname(size_t index) { return index < 32 ? name(index + traits::V0) : "illegal"; }
    inline const char* sew_name(size_t bits) {
        switch(bits) {
        case 0b000:
            return "e8";
        case 0b001:
            return "e16";
        case 0b010:
            return "e32";
        case 0b011:
            return "e64";
        default:
            return "illegal";
        }
    }
    inline const char* lmul_name(size_t bits) {
        switch(bits) {
        case 0b101:
            return "mf8";
        case 0b110:
            return "mf4";
        case 0b111:
            return "mf2";
        case 0b000:
            return "m1";
        case 0b001:
            return "m2";
        case 0b010:
            return "m4";
        case 0b011:
            return "m8";
        default:
            return "illegal";
        }
    }
    inline const char* ma_name(bool ma) { return ma ? "ma" : "mu"; }
    inline const char* ta_name(bool ta) { return ta ? "ta" : "tu"; }
<%}%>
    void gen_instr_prologue(jit_holder& jh);
    void gen_instr_epilogue(jit_holder& jh);
    inline void gen_raise(jit_holder& jh, uint16_t trap_id, uint16_t cause);
    inline void gen_lower(jit_holder& jh);
    template <typename T, typename = typename std::enable_if<std::is_integral<T>::value>::type> void gen_set_tval(jit_holder& jh, T new_tval) ;
    void gen_set_tval(jit_holder& jh, x86_reg_t _new_tval) ;

    template<unsigned W, typename U, typename S = typename std::make_signed<U>::type>
    inline S sext(U from) {
        auto mask = (1ULL<<W) - 1;
        auto sign_mask = 1ULL<<(W-1);
        return (from & mask) | ((from & sign_mask) ? ~mask : 0);
    }
    inline void raise(uint16_t trap_id, uint16_t cause){
        auto trap_val =  0x80ULL << 24 | (cause << 16) | trap_id;
        this->core.reg.trap_state = trap_val;
    }

<%functions.each{ it.eachLine { %>
    ${it}<%}
}%>
private:
    /****************************************************************************
     * start opcode definitions
     ****************************************************************************/
    struct instruction_descriptor {
        uint32_t length;
        uint32_t value;
        uint32_t mask;
        compile_func op;
    };

    const std::array<instruction_descriptor, ${instructions.size()}> instr_descr = {{
         /* entries are: size, valid value, valid mask, function ptr */<%instructions.each{instr -> %>
        /* instruction ${instr.instruction.name}, encoding '${instr.encoding}' */
        {${instr.length}, ${instr.encoding}, ${instr.mask}, &this_class::__${generator.functionName(instr.name)}},<%}%>
    }};

    //needs to be declared after instr_descr
    decoder instr_decoder;

    /* instruction definitions */<%instructions.eachWithIndex{instr, idx -> %>
    /* instruction ${idx}: ${instr.name} */
    continuation_e __${generator.functionName(instr.name)}(virt_addr_t& pc, code_word_t instr, jit_holder& jh){
        uint64_t PC = pc.val;
        <%instr.fields.eachLine{%>${it}
        <%}%>if(this->disass_enabled){
            /* generate disass */
            <%instr.disass.eachLine{%>
            ${it}<%}%>
            InvokeNode* call_print_disass;
            char* mnemonic_ptr = strdup(mnemonic.c_str());
            jh.disass_collection.push_back(mnemonic_ptr);
            jh.cc.invoke(&call_print_disass, &print_disass, FuncSignature::build<void, void *, uint64_t, char *>());
            call_print_disass->setArg(0, jh.arch_if_ptr);
            call_print_disass->setArg(1, pc.val);
            call_print_disass->setArg(2, mnemonic_ptr);

        }
        x86::Compiler& cc = jh.cc;
        cc.comment(fmt::format("${instr.name}_{:#x}:",pc.val).c_str());
        gen_sync(jh, PRE_SYNC, ${idx});
        mov(cc, jh.pc, pc.val);
        gen_set_tval(jh, instr);
        pc = pc+${instr.length/8};
        mov(cc, jh.next_pc, pc.val);
        cc.mov(get_ptr_for(jh, traits::INSTRUCTION), instr);

        gen_instr_prologue(jh);
        /*generate behavior*/
        <%instr.behavior.eachLine{%>${it}
        <%}%>
        gen_sync(jh, POST_SYNC, ${idx});
        gen_instr_epilogue(jh);
    	return returnValue;        
    }
    <%}%>
    /****************************************************************************
     * end opcode definitions
     ****************************************************************************/
    continuation_e illegal_instruction(virt_addr_t &pc, code_word_t instr, jit_holder& jh ) {
        x86::Compiler& cc = jh.cc;
        if(this->disass_enabled){          
            auto mnemonic = std::string("illegal_instruction");
            InvokeNode* call_print_disass;
            char* mnemonic_ptr = strdup(mnemonic.c_str());
            jh.disass_collection.push_back(mnemonic_ptr);
            jh.cc.invoke(&call_print_disass, &print_disass, FuncSignature::build<void, void *, uint64_t, char *>());
            call_print_disass->setArg(0, jh.arch_if_ptr);
            call_print_disass->setArg(1, pc.val);
            call_print_disass->setArg(2, mnemonic_ptr);
        }
        cc.comment(fmt::format("illegal_instruction{:#x}:",pc.val).c_str());
        gen_sync(jh, PRE_SYNC, instr_descr.size());
        mov(cc, jh.pc, pc.val);
        gen_set_tval(jh, instr);
        pc = pc + ((instr & 3) == 3 ? 4 : 2);
        mov(cc, jh.next_pc, pc.val);
        gen_instr_prologue(jh);
        gen_raise(jh, 0, 2);
        gen_sync(jh, POST_SYNC, instr_descr.size());
        gen_instr_epilogue(jh);
        return ILLEGAL_INSTR;
    }
};

template <typename ARCH> vm_impl<ARCH>::vm_impl() { this(new ARCH()); }

template <typename ARCH>
vm_impl<ARCH>::vm_impl(ARCH &core, unsigned core_id, unsigned cluster_id)
: vm_base<ARCH>(core, core_id, cluster_id)
, instr_decoder([this]() {
        std::vector<generic_instruction_descriptor> g_instr_descr;
        g_instr_descr.reserve(instr_descr.size());
        for (uint32_t i = 0; i < instr_descr.size(); ++i) {
            generic_instruction_descriptor new_instr_descr {instr_descr[i].value, instr_descr[i].mask, i};
            g_instr_descr.push_back(new_instr_descr);
        }
        return std::move(g_instr_descr);
    }()) {}

template <typename ARCH>
continuation_e vm_impl<ARCH>::gen_single_inst_behavior(virt_addr_t &pc, jit_holder& jh) {
    enum {TRAP_ID=1<<16};
    code_word_t instr = 0;
    phys_addr_t paddr(pc);
    auto *const data = (uint8_t *)&instr;
    auto res = this->core.read(paddr, 4, data);
    if (res != iss::Ok)
        return ILLEGAL_FETCH;
    if (instr == 0x0000006f || (instr&0xffff)==0xa001)
        return JUMP_TO_SELF;
    uint32_t inst_index = instr_decoder.decode_instr(instr);
    compile_func f = nullptr;
    if(inst_index < instr_descr.size())
        f = instr_descr[inst_index].op;
    if (f == nullptr) 
        f = &this_class::illegal_instruction;
    return (this->*f)(pc, instr, jh);
}
template <typename ARCH>
void vm_impl<ARCH>::gen_instr_prologue(jit_holder& jh) {
    auto& cc = jh.cc;

    x86_reg_t current_trap_state = get_reg_for(cc, traits::TRAP_STATE);
    mov(cc, current_trap_state, get_ptr_for(jh, traits::TRAP_STATE));
    mov(cc, get_ptr_for(jh, traits::PENDING_TRAP), current_trap_state);
    cc.comment("//Instruction prologue end");

}
template <typename ARCH>
void vm_impl<ARCH>::gen_instr_epilogue(jit_holder& jh) {
    auto& cc = jh.cc;

    cc.comment("//Instruction epilogue begin");
    cc.inc(get_ptr_for(jh, traits::CYCLE));
    x86_reg_t current_trap_state = get_reg_for(cc, traits::TRAP_STATE);
    mov(cc, current_trap_state, get_ptr_for(jh, traits::TRAP_STATE));
    cmp(cc, current_trap_state, 0);
    cc.jne(jh.trap_entry);
    cc.inc(get_ptr_for(jh, traits::ICOUNT));
    cc.inc(get_ptr_for(jh, traits::INSTRET));
    cc.comment("//Instruction epilogue end");

}
template <typename ARCH>
void vm_impl<ARCH>::gen_block_prologue(jit_holder& jh){
    jh.pc = load_reg_from_mem_Gp(jh, traits::PC);
    jh.next_pc = load_reg_from_mem_Gp(jh, traits::NEXT_PC);
    jh.globals.resize(GLOBALS_SIZE);
    jh.globals[TVAL] = get_reg_Gp(jh.cc, 64, false);
}
template <typename ARCH>
void vm_impl<ARCH>::gen_block_epilogue(jit_holder& jh){
    x86::Compiler& cc = jh.cc;
    cc.comment("//gen_block_epilogue");
    cc.ret(jh.next_pc);

    cc.bind(jh.trap_entry);
    this->write_back(jh);

    x86::Gp current_trap_state = get_reg_for_Gp(cc, traits::TRAP_STATE);
    mov(cc, current_trap_state, get_ptr_for(jh, traits::TRAP_STATE));

    x86::Gp current_pc = get_reg_for_Gp(cc, traits::PC);
    mov(cc, current_pc, get_ptr_for(jh, traits::PC));

    InvokeNode* call_enter_trap;
    cc.invoke(&call_enter_trap, &enter_trap, FuncSignature::build<uint64_t, void*, uint64_t, uint64_t, uint64_t>());
    call_enter_trap->setArg(0, jh.arch_if_ptr);
    call_enter_trap->setArg(1, current_trap_state);
    call_enter_trap->setArg(2, current_pc);
    call_enter_trap->setArg(3, jh.globals[TVAL]);

    x86_reg_t current_next_pc = get_reg_for(cc, traits::NEXT_PC);
    mov(cc, current_next_pc, get_ptr_for(jh, traits::NEXT_PC));
    mov(cc, jh.next_pc, current_next_pc);

    mov(cc, get_ptr_for(jh, traits::LAST_BRANCH), static_cast<int>(UNKNOWN_JUMP));
    cc.ret(jh.next_pc);
}
template <typename ARCH>
inline void vm_impl<ARCH>::gen_raise(jit_holder& jh, uint16_t trap_id, uint16_t cause) {
    auto& cc = jh.cc;
    auto tmp1 = get_reg_for(cc, traits::TRAP_STATE);
    mov(cc, tmp1, 0x80ULL << 24 | (cause << 16) | trap_id);
    mov(cc, get_ptr_for(jh, traits::TRAP_STATE), tmp1);
    cc.jmp(jh.trap_entry);
}
template <typename ARCH>
inline void vm_impl<ARCH>::gen_lower(jit_holder& jh) {
    auto& cc = jh.cc;
    auto tmp1 = get_reg_for(cc, traits::TRAP_STATE);
    mov(cc, tmp1, 0);
    mov(cc, get_ptr_for(jh, traits::TRAP_STATE), tmp1);
}
template <typename ARCH>
template <typename T, typename>
void vm_impl<ARCH>::gen_set_tval(jit_holder& jh, T new_tval) {
        mov(jh.cc, jh.globals[TVAL], new_tval);
    }
template <typename ARCH>
void vm_impl<ARCH>::gen_set_tval(jit_holder& jh, x86_reg_t _new_tval) {
    if(nonstd::holds_alternative<x86::Gp>(_new_tval)) {
        x86::Gp new_tval = nonstd::get<x86::Gp>(_new_tval);
        if(new_tval.size() < 8)
            new_tval = gen_ext_Gp(jh.cc, new_tval, 64, false);
        mov(jh.cc, jh.globals[TVAL], new_tval);
    } else {
        throw std::runtime_error("Variant not supported in gen_set_tval");
    }
}

} // namespace tgc5c

template <>
std::unique_ptr<vm_if> create<arch::${coreDef.name.toLowerCase()}>(arch::${coreDef.name.toLowerCase()} *core, unsigned short port, bool dump) {
    auto ret = new ${coreDef.name.toLowerCase()}::vm_impl<arch::${coreDef.name.toLowerCase()}>(*core, dump);
    if (port != 0) debugger::server<debugger::gdb_session>::run_server(ret, port);
    return std::unique_ptr<vm_if>(ret);
}
} // namespace asmjit
} // namespace iss

#include <iss/arch/riscv_hart_m_p.h>
#include <iss/arch/riscv_hart_mu_p.h>
#include <iss/arch/riscv_hart_msu_vp.h>
#include <iss/factory.h>
namespace iss {
namespace {
<% if(instructions.find{it.instruction.name.toLowerCase() == "sret"}) {%>
volatile std::array<bool, 3> dummy = {
        core_factory::instance().register_creator("${coreDef.name.toLowerCase()}_msu:asmjit", [](unsigned port, void* init_data) -> std::tuple<cpu_ptr, vm_ptr>{
            auto* cpu = new iss::arch::riscv_hart_msu_vp<iss::arch::${coreDef.name.toLowerCase()}>();
		    auto vm = new asmjit::${coreDef.name.toLowerCase()}::vm_impl<arch::${coreDef.name.toLowerCase()}>(*cpu, false);
		    if (port != 0) debugger::server<debugger::gdb_session>::run_server(vm, port);
            if(init_data){
                auto* cb = reinterpret_cast<semihosting_cb_t<arch::traits<arch::${coreDef.name.toLowerCase()}>::reg_t>*>(init_data);
                cpu->set_semihosting_callback(*cb);
            }
            return {cpu_ptr{cpu}, vm_ptr{vm}};
        }),<% } else { %>
volatile std::array<bool, 2> dummy = {<%}%>
        core_factory::instance().register_creator("${coreDef.name.toLowerCase()}_m:asmjit", [](unsigned port, void* init_data) -> std::tuple<cpu_ptr, vm_ptr>{
            auto* cpu = new iss::arch::riscv_hart_m_p<iss::arch::${coreDef.name.toLowerCase()}>();
		    auto vm = new asmjit::${coreDef.name.toLowerCase()}::vm_impl<arch::${coreDef.name.toLowerCase()}>(*cpu, false);
		    if (port != 0) debugger::server<debugger::gdb_session>::run_server(vm, port);
            if(init_data){
                auto* cb = reinterpret_cast<semihosting_cb_t<arch::traits<arch::${coreDef.name.toLowerCase()}>::reg_t>*>(init_data);
                cpu->set_semihosting_callback(*cb);
            }
            return {cpu_ptr{cpu}, vm_ptr{vm}};
        }),
        core_factory::instance().register_creator("${coreDef.name.toLowerCase()}_mu:asmjit", [](unsigned port, void* init_data) -> std::tuple<cpu_ptr, vm_ptr>{
            auto* cpu = new iss::arch::riscv_hart_mu_p<iss::arch::${coreDef.name.toLowerCase()}>();
		    auto vm = new asmjit::${coreDef.name.toLowerCase()}::vm_impl<arch::${coreDef.name.toLowerCase()}>(*cpu, false);
		    if (port != 0) debugger::server<debugger::gdb_session>::run_server(vm, port);
            if(init_data){
                auto* cb = reinterpret_cast<semihosting_cb_t<arch::traits<arch::${coreDef.name.toLowerCase()}>::reg_t>*>(init_data);
                cpu->set_semihosting_callback(*cb);
            }
            return {cpu_ptr{cpu}, vm_ptr{vm}};
        })
};
}
}
// clang-format on
